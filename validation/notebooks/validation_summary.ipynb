{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kepler-ECG: Validation Summary\n",
    "## Marconi QTc Formula — Reproducibility Notebook\n",
    "\n",
    "**Paper:** Marconi A. *Derivation and Validation of an Improved Method for Correcting the QT Interval.* Submitted to JACC, February 2026.\n",
    "\n",
    "**Formula:** `QTc = QT + 125/RR − 125` (QT in ms, RR in seconds)\n",
    "\n",
    "This notebook provides an interactive walkthrough of all key results. It loads the preprocessed data, computes every metric reported in the paper, and generates publication-quality figures.\n",
    "\n",
    "**Critical methodology notes:**\n",
    "- The polynomial reference standard is fitted **per-dataset** (not on pooled data)\n",
    "- |r(QTc, HR)| is computed **per-dataset**, then **population-weighted** by dataset size\n",
    "- False positive rate = FP / (FP + TN) **against the polynomial reference** (not raw positive rate)\n",
    "- If `QTc_reference_ms` is present in the data files, it is used directly\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.ticker as ticker\n",
    "    import seaborn as sns\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"notebook\", font_scale=1.1)\n",
    "    HAS_PLOT = True\n",
    "except ImportError:\n",
    "    HAS_PLOT = False\n",
    "    print(\"matplotlib/seaborn not available — tables only.\")\n",
    "\n",
    "DATA_DIR = Path(\"../../results\")  # Adjust if needed\n",
    "OUTPUT_DIR = Path(\"../../results/reproduce\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DERIVATION_DATASETS = [\"ptb-xl\", \"chapman\", \"cpsc-2018\", \"georgia\", \"mimic-iv-ecg\", \"code-15\"]\n",
    "EXTERNAL_DATASETS = [\"ludb\"]\n",
    "\n",
    "SEX_MALE, SEX_FEMALE = 0, 1\n",
    "QTC_THRESHOLD = {SEX_MALE: 450.0, SEX_FEMALE: 460.0}\n",
    "\n",
    "# Formula definitions\n",
    "def marconi(qt, rr, hr):     return qt + 125.0 / rr - 125.0\n",
    "def bazett(qt, rr, hr):      return qt / np.sqrt(rr)\n",
    "def fridericia(qt, rr, hr):  return qt / np.cbrt(rr)\n",
    "def framingham(qt, rr, hr):  return qt + 154.0 * (1.0 - rr)\n",
    "def hodges(qt, rr, hr):      return qt + 1.75 * (hr - 60.0)\n",
    "\n",
    "FORMULAS = {\"Marconi\": marconi, \"Bazett\": bazett, \"Fridericia\": fridericia,\n",
    "            \"Framingham\": framingham, \"Hodges\": hodges}\n",
    "\n",
    "FORMULA_COLORS = {\"Marconi\": \"#1f77b4\", \"Bazett\": \"#d62728\", \"Fridericia\": \"#ff7f0e\",\n",
    "                  \"Framingham\": \"#2ca02c\", \"Hodges\": \"#9467bd\"}\n",
    "\n",
    "N_BOOTSTRAP = 1000\n",
    "POLY_DEGREE_REF = 6  # Per-dataset polynomial reference\n",
    "\n",
    "print(\"Setup complete ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(name):\n",
    "    candidates = [\n",
    "        DATA_DIR / name / \"qtc\" / f\"{name}_qtc_preparation.csv\",\n",
    "        DATA_DIR / name / f\"{name}_qtc_preparation.csv\",\n",
    "    ]\n",
    "    for path in candidates:\n",
    "        if path.exists():\n",
    "            try: df = pd.read_csv(path, sep=\";\", decimal=\",\")\n",
    "            except: df = pd.read_csv(path)\n",
    "            renames = {}\n",
    "            for c in df.columns:\n",
    "                cl = c.lower()\n",
    "                if cl in (\"qt_interval_ms\", \"qt_ms\", \"qt\"):             renames[c] = \"QT_ms\"\n",
    "                elif cl in (\"rr_interval_ms\", \"rr_ms\"):                  renames[c] = \"RR_ms\"\n",
    "                elif cl in (\"rr_interval_s\", \"rr_s\", \"rr\"):              renames[c] = \"RR_s\"\n",
    "                elif cl in (\"heart_rate\", \"hr\", \"heart_rate_bpm\"):       renames[c] = \"HR\"\n",
    "                elif cl == \"sex\":                                         renames[c] = \"sex\"\n",
    "                elif cl == \"age\":                                         renames[c] = \"age\"\n",
    "                elif cl in (\"qtc_reference_ms\", \"qtc_ref_ms\"):            renames[c] = \"QTc_reference_ms\"\n",
    "                elif cl in (\"primary_superclass\",):                       renames[c] = \"superclass\"\n",
    "            df = df.rename(columns=renames)\n",
    "            for col in [\"QT_ms\", \"RR_s\", \"RR_ms\", \"HR\", \"age\", \"sex\", \"QTc_reference_ms\"]:\n",
    "                if col in df.columns: df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "            if \"RR_s\" not in df.columns and \"RR_ms\" in df.columns: df[\"RR_s\"] = df[\"RR_ms\"] / 1000.0\n",
    "            if \"HR\" not in df.columns and \"RR_s\" in df.columns:    df[\"HR\"] = 60.0 / df[\"RR_s\"]\n",
    "            df[\"source\"] = name\n",
    "            return df\n",
    "    return None\n",
    "\n",
    "datasets = {}\n",
    "for name in DERIVATION_DATASETS + EXTERNAL_DATASETS:\n",
    "    df = load_dataset(name)\n",
    "    if df is not None:\n",
    "        datasets[name] = df\n",
    "        print(f\"  ✓ {name:15s} {len(df):>10,} records\")\n",
    "    else:\n",
    "        print(f\"  ✗ {name:15s} not found\")\n",
    "\n",
    "print(f\"\\nLoaded {len(datasets)} datasets, {sum(len(v) for v in datasets.values()):,} total records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute QTc Values and Per-Dataset Polynomial Reference\n",
    "\n",
    "**Critical:** The polynomial reference is fitted independently for each dataset, not on pooled data. This ensures the reference standard is not biased by any single dataset's QT-RR distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df):\n",
    "    \"\"\"Compute QTc for all formulas + PER-DATASET polynomial reference.\"\"\"\n",
    "    qt, rr, hr = df[\"QT_ms\"].values, df[\"RR_s\"].values, df[\"HR\"].values\n",
    "    for name, func in FORMULAS.items():\n",
    "        df[f\"QTc_{name}\"] = func(qt, rr, hr)\n",
    "    df[\"threshold\"] = df[\"sex\"].map(QTC_THRESHOLD)\n",
    "    for name in FORMULAS:\n",
    "        df[f\"prolonged_{name}\"] = df[f\"QTc_{name}\"] >= df[\"threshold\"]\n",
    "\n",
    "    # Per-dataset polynomial reference (use pre-computed if available)\n",
    "    if \"QTc_reference_ms\" in df.columns and df[\"QTc_reference_ms\"].notna().sum() > 100:\n",
    "        df[\"QTc_reference\"] = df[\"QTc_reference_ms\"]\n",
    "    else:\n",
    "        coeffs = np.polyfit(rr, qt, POLY_DEGREE_REF)\n",
    "        df[\"QTc_reference\"] = qt - np.polyval(coeffs, rr) + np.mean(qt)\n",
    "\n",
    "    df[\"prolonged_reference\"] = df[\"QTc_reference\"] >= df[\"threshold\"]\n",
    "    return df\n",
    "\n",
    "# Prepare EACH dataset independently\n",
    "for name in datasets:\n",
    "    datasets[name] = prepare_dataset(datasets[name])\n",
    "    r = abs(stats.pearsonr(datasets[name][\"QTc_Marconi\"].values,\n",
    "                           datasets[name][\"HR\"].values)[0])\n",
    "    print(f\"  {name:15s} Marconi |r| = {r:.4f}\")\n",
    "\n",
    "# Build pooled (per-dataset references preserved in each row)\n",
    "derivation = [datasets[k] for k in DERIVATION_DATASETS if k in datasets]\n",
    "pooled = pd.concat(derivation, ignore_index=True)\n",
    "ludb = datasets.get(\"ludb\")\n",
    "\n",
    "print(f\"\\nPooled derivation: {len(pooled):,} ECGs from {len(derivation)} datasets\")\n",
    "if ludb is not None:\n",
    "    print(f\"LUDB external:     {len(ludb):,} ECGs (expert-annotated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Core Metric Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_abs_r(qtc, hr):\n",
    "    mask = np.isfinite(qtc) & np.isfinite(hr)\n",
    "    if mask.sum() < 10: return np.nan\n",
    "    return abs(stats.pearsonr(qtc[mask], hr[mask])[0])\n",
    "\n",
    "def population_weighted_r(formula_name, ds_names=DERIVATION_DATASETS):\n",
    "    \"\"\"Population-weighted |r| across datasets.\"\"\"\n",
    "    total_n, wsum = 0, 0.0\n",
    "    for ds in ds_names:\n",
    "        if ds not in datasets: continue\n",
    "        df = datasets[ds]\n",
    "        n = len(df)\n",
    "        r = pearson_abs_r(df[f\"QTc_{formula_name}\"].values, df[\"HR\"].values)\n",
    "        if not np.isnan(r):\n",
    "            wsum += r * n; total_n += n\n",
    "    return wsum / total_n if total_n > 0 else np.nan\n",
    "\n",
    "def bootstrap_weighted_r(formula_name, ds_names=DERIVATION_DATASETS, n_boot=N_BOOTSTRAP):\n",
    "    \"\"\"Bootstrap 95% CI for population-weighted |r|.\"\"\"\n",
    "    rng = np.random.default_rng(42)\n",
    "    ds_data = {}\n",
    "    for ds in ds_names:\n",
    "        if ds not in datasets: continue\n",
    "        df = datasets[ds]\n",
    "        qtc, hr = df[f\"QTc_{formula_name}\"].values, df[\"HR\"].values\n",
    "        m = np.isfinite(qtc) & np.isfinite(hr)\n",
    "        ds_data[ds] = (qtc[m], hr[m])\n",
    "\n",
    "    boot_rs = np.empty(n_boot)\n",
    "    for i in range(n_boot):\n",
    "        wsum, tn = 0.0, 0\n",
    "        for ds, (qtc, hr) in ds_data.items():\n",
    "            n = len(qtc)\n",
    "            idx = rng.integers(0, n, size=n)\n",
    "            r = abs(stats.pearsonr(qtc[idx], hr[idx])[0])\n",
    "            wsum += r * n; tn += n\n",
    "        boot_rs[i] = wsum / tn if tn > 0 else np.nan\n",
    "    return (np.nanpercentile(boot_rs, 2.5), np.nanpercentile(boot_rs, 97.5))\n",
    "\n",
    "def classification_metrics(y_true, y_pred):\n",
    "    tp = int(np.sum(y_true & y_pred))\n",
    "    fp = int(np.sum(~y_true & y_pred))\n",
    "    tn = int(np.sum(~y_true & ~y_pred))\n",
    "    fn = int(np.sum(y_true & ~y_pred))\n",
    "    return {\"TP\": tp, \"FP\": fp, \"TN\": tn, \"FN\": fn,\n",
    "            \"Sens\": tp/(tp+fn) if (tp+fn) > 0 else np.nan,\n",
    "            \"Spec\": tn/(tn+fp) if (tn+fp) > 0 else np.nan,\n",
    "            \"PPV\": tp/(tp+fp) if (tp+fp) > 0 else np.nan,\n",
    "            \"NPV\": tn/(tn+fn) if (tn+fn) > 0 else np.nan,\n",
    "            \"FP_rate\": fp/(fp+tn) if (fp+tn) > 0 else np.nan}\n",
    "\n",
    "print(\"Helper functions defined ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Table 2 — Heart Rate Independence (Primary Endpoint)\n",
    "\n",
    "The primary endpoint is the **population-weighted** absolute Pearson correlation |r(QTc, HR)|. Each dataset's |r| is weighted by its size.\n",
    "\n",
    "False positive rate = FP / (FP + TN) **against the per-dataset polynomial reference**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = pooled[\"prolonged_reference\"].values  # Per-dataset references, now pooled\n",
    "n_ref_normal = int(np.sum(~ref))\n",
    "\n",
    "rows = []\n",
    "for name in FORMULAS:\n",
    "    r_w = population_weighted_r(name)\n",
    "    ci_lo, ci_hi = bootstrap_weighted_r(name)\n",
    "\n",
    "    # FP rate against reference\n",
    "    pred = pooled[f\"prolonged_{name}\"].values\n",
    "    fp = int(np.sum(~ref & pred))\n",
    "    fp_rate = fp / n_ref_normal * 100\n",
    "\n",
    "    rows.append({\"Formula\": name, \"|r|\": r_w, \"CI_lo\": ci_lo, \"CI_hi\": ci_hi, \"FP%\": fp_rate})\n",
    "\n",
    "table2 = pd.DataFrame(rows).sort_values(\"|r|\")\n",
    "table2[\"Rank\"] = range(1, len(table2) + 1)\n",
    "baz_r = table2.loc[table2[\"Formula\"] == \"Bazett\", \"|r|\"].values[0]\n",
    "table2[\"vs Bazett\"] = table2[\"|r|\"].apply(\n",
    "    lambda x: f\"{baz_r/x:.1f}x better\" if x < baz_r else\n",
    "              (f\"{x/baz_r:.1f}x worse\" if x > baz_r else \"ref\"))\n",
    "\n",
    "print(f\"Pooled derivation N = {len(pooled):,}\")\n",
    "print(f\"Reference-normal N = {n_ref_normal:,}\\n\")\n",
    "print(table2[[\"Rank\", \"Formula\", \"|r|\", \"CI_lo\", \"CI_hi\", \"vs Bazett\", \"FP%\"]].to_string(\n",
    "    index=False, float_format=\"%.3f\"))\n",
    "\n",
    "print(\"\\n--- Per-dataset |r| breakdown ---\")\n",
    "for ds in DERIVATION_DATASETS:\n",
    "    if ds not in datasets: continue\n",
    "    df = datasets[ds]\n",
    "    r_m = pearson_abs_r(df[\"QTc_Marconi\"].values, df[\"HR\"].values)\n",
    "    r_b = pearson_abs_r(df[\"QTc_Bazett\"].values, df[\"HR\"].values)\n",
    "    print(f\"  {ds:15s} (N={len(df):>7,}): Marconi={r_m:.4f}  Bazett={r_b:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Figure 4 — QTc vs Heart Rate Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_PLOT:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10), sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    rng = np.random.default_rng(42)\n",
    "    n_plot = min(30000, len(pooled))\n",
    "    idx = rng.choice(len(pooled), size=n_plot, replace=False)\n",
    "    sub = pooled.iloc[idx]\n",
    "\n",
    "    for i, (name, color) in enumerate(FORMULA_COLORS.items()):\n",
    "        ax = axes[i]\n",
    "        ax.scatter(sub[\"HR\"], sub[f\"QTc_{name}\"], s=0.3, alpha=0.15, color=color, rasterized=True)\n",
    "        hr_s, qtc_s = sub[\"HR\"].values, sub[f\"QTc_{name}\"].values\n",
    "        m = np.isfinite(hr_s) & np.isfinite(qtc_s)\n",
    "        z = np.polyfit(hr_s[m], qtc_s[m], 1)\n",
    "        ax.plot(np.linspace(30, 150, 100), np.polyval(z, np.linspace(30, 150, 100)), \"r-\", lw=2)\n",
    "        ax.axhline(450, color=\"gray\", ls=\"--\", alpha=0.5, lw=0.8)\n",
    "        ax.axhline(460, color=\"gray\", ls=\"--\", alpha=0.5, lw=0.8)\n",
    "        r_val = population_weighted_r(name)\n",
    "        ax.set_title(f\"{name}  |r|ₚ = {r_val:.3f}\", fontsize=13, fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Heart Rate (bpm)\")\n",
    "        if i % 3 == 0: ax.set_ylabel(\"QTc (ms)\")\n",
    "        ax.set_xlim(30, 150); ax.set_ylim(250, 650)\n",
    "\n",
    "    # Bar chart\n",
    "    ax = axes[5]\n",
    "    names = list(FORMULA_COLORS.keys())\n",
    "    rs = [population_weighted_r(n) for n in names]\n",
    "    bars = ax.bar(names, rs, color=[FORMULA_COLORS[n] for n in names], edgecolor=\"black\", lw=0.5)\n",
    "    ax.axhline(0.10, color=\"red\", ls=\"--\", lw=1, label=\"|r| = 0.10\")\n",
    "    ax.set_ylabel(\"|r(QTc, HR)|ₚ\"); ax.set_title(\"Population-Weighted |r|\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / \"figure4_reproduced.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Plotting not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Table 3 — Stratified Performance by HR Zone and Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strata_defs = {\n",
    "    \"Bradycardia (<60)\":  lambda df: df[\"HR\"] < 60,\n",
    "    \"Normal (60-100)\":    lambda df: (df[\"HR\"] >= 60) & (df[\"HR\"] <= 100),\n",
    "    \"Tachycardia (>100)\": lambda df: df[\"HR\"] > 100,\n",
    "    \"Age <40\":            lambda df: df[\"age\"] < 40,\n",
    "    \"Age 40-65\":          lambda df: (df[\"age\"] >= 40) & (df[\"age\"] < 65),\n",
    "    \"Age >65\":            lambda df: df[\"age\"] >= 65,\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for sname, mask_fn in strata_defs.items():\n",
    "    total_n = 0\n",
    "    f_wsum = {f: 0.0 for f in FORMULAS}\n",
    "    for ds in DERIVATION_DATASETS:\n",
    "        if ds not in datasets: continue\n",
    "        df = datasets[ds]\n",
    "        sub = df[mask_fn(df)]\n",
    "        n = len(sub)\n",
    "        if n < 30: continue\n",
    "        total_n += n\n",
    "        for fname in FORMULAS:\n",
    "            r = pearson_abs_r(sub[f\"QTc_{fname}\"].values, sub[\"HR\"].values)\n",
    "            if not np.isnan(r): f_wsum[fname] += r * n\n",
    "    if total_n < 30: continue\n",
    "    row = {\"Stratum\": sname, \"N\": f\"{total_n:,}\"}\n",
    "    for fname in FORMULAS:\n",
    "        row[fname] = round(f_wsum[fname] / total_n, 3)\n",
    "    row[\"Improvement\"] = f\"{row['Bazett']/row['Marconi']:.1f}x\" if row[\"Marconi\"] > 0 else \"—\"\n",
    "    rows.append(row)\n",
    "\n",
    "table3 = pd.DataFrame(rows)\n",
    "print(table3.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Table 5 — External Validation (LUDB Gold Standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ludb is not None:\n",
    "    hr_l = ludb[\"HR\"].values\n",
    "    ref_l = ludb[\"prolonged_reference\"].values\n",
    "    rows = []\n",
    "    for name in FORMULAS:\n",
    "        qtc = ludb[f\"QTc_{name}\"].values\n",
    "        r_abs = pearson_abs_r(qtc, hr_l)\n",
    "        cm = classification_metrics(ref_l, ludb[f\"prolonged_{name}\"].values)\n",
    "        rows.append({\"Formula\": name, \"|r|\": round(r_abs, 3),\n",
    "                      \"Sens%\": round(cm[\"Sens\"]*100, 1) if not np.isnan(cm[\"Sens\"]) else \"N/A\",\n",
    "                      \"Spec%\": round(cm[\"Spec\"]*100, 1) if not np.isnan(cm[\"Spec\"]) else \"N/A\",\n",
    "                      \"FP\": cm[\"FP\"], \"FN\": cm[\"FN\"],\n",
    "                      \"FP Rate%\": round(cm[\"FP_rate\"]*100, 1) if not np.isnan(cm[\"FP_rate\"]) else \"N/A\"})\n",
    "    table5 = pd.DataFrame(rows).sort_values(\"|r|\")\n",
    "    print(f\"LUDB N = {len(ludb)}\\n\")\n",
    "    print(table5.to_string(index=False))\n",
    "else:\n",
    "    print(\"LUDB not loaded — skipping.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Table 6 — Severity-Stratified Misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = pooled[\"prolonged_reference\"].values\n",
    "threshold = pooled[\"threshold\"].values\n",
    "rows = []\n",
    "for fname in FORMULAS:\n",
    "    qtc = pooled[f\"QTc_{fname}\"].values\n",
    "    pred = pooled[f\"prolonged_{fname}\"].values\n",
    "    dist = np.abs(qtc - threshold)\n",
    "    fp_mask, fn_mask = ~ref & pred, ref & ~pred\n",
    "    rows.append({\n",
    "        \"Formula\": fname,\n",
    "        \"FP ≤10ms\": int(np.sum(fp_mask & (dist <= 10))),\n",
    "        \"FP >10ms\": int(np.sum(fp_mask & (dist > 10))),\n",
    "        \"FP Total\": int(np.sum(fp_mask)),\n",
    "        \"FN ≤10ms\": int(np.sum(fn_mask & (dist <= 10))),\n",
    "        \"FN >10ms\": int(np.sum(fn_mask & (dist > 10))),\n",
    "        \"FN Total\": int(np.sum(fn_mask)),\n",
    "    })\n",
    "table6 = pd.DataFrame(rows)\n",
    "print(table6.to_string(index=False))\n",
    "\n",
    "m_fp = table6.loc[table6[\"Formula\"]==\"Marconi\", \"FP Total\"].values[0]\n",
    "b_fp = table6.loc[table6[\"Formula\"]==\"Bazett\", \"FP Total\"].values[0]\n",
    "print(f\"\\nFP reduction: Bazett {b_fp:,} → Marconi {m_fp:,} ({b_fp/m_fp:.1f}x)\" if m_fp > 0 else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Diagnostic Accuracy Summary (Marconi vs Bazett)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = pooled[\"prolonged_reference\"].values\n",
    "\n",
    "for fname in [\"Marconi\", \"Bazett\"]:\n",
    "    cm = classification_metrics(ref, pooled[f\"prolonged_{fname}\"].values)\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"  {fname} vs Polynomial Reference\")\n",
    "    print(f\"{'='*40}\")\n",
    "    print(f\"  Sensitivity: {cm['Sens']*100:.1f}%\")\n",
    "    print(f\"  Specificity: {cm['Spec']*100:.1f}%\")\n",
    "    print(f\"  PPV:         {cm['PPV']*100:.1f}%\")\n",
    "    print(f\"  NPV:         {cm['NPV']*100:.1f}%\")\n",
    "    print(f\"  FP:          {cm['FP']:,}\")\n",
    "    print(f\"  FN:          {cm['FN']:,}\")\n",
    "    print(f\"  FP Rate:     {cm['FP_rate']*100:.2f}%\")\n",
    "\n",
    "# NNT\n",
    "cm_m = classification_metrics(ref, pooled[\"prolonged_Marconi\"].values)\n",
    "cm_b = classification_metrics(ref, pooled[\"prolonged_Bazett\"].values)\n",
    "print(f\"\\nFP eliminated: {cm_b['FP'] - cm_m['FP']:,}\")\n",
    "print(f\"NNT: {len(pooled) / (cm_b['FP'] - cm_m['FP']):.1f}\" if cm_b['FP'] > cm_m['FP'] else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Clinical Impact Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_PLOT:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Panel A: population-weighted |r|\n",
    "    ax = axes[0]\n",
    "    names = list(FORMULAS.keys())\n",
    "    rs = [population_weighted_r(n) for n in names]\n",
    "    colors = [FORMULA_COLORS[n] for n in names]\n",
    "    order = np.argsort(rs)\n",
    "    ax.barh([names[i] for i in order], [rs[i] for i in order],\n",
    "            color=[colors[i] for i in order], edgecolor=\"black\", lw=0.5)\n",
    "    ax.axvline(0.10, color=\"red\", ls=\"--\", lw=1.5, label=\"Clinical threshold\")\n",
    "    ax.set_xlabel(\"|r(QTc, HR)|ₚ\", fontsize=12)\n",
    "    ax.set_title(\"A. Heart Rate Independence (pop-weighted)\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.legend(loc=\"lower right\"); ax.set_xlim(0, max(rs) * 1.15)\n",
    "\n",
    "    # Panel B: FP rates against reference\n",
    "    ax = axes[1]\n",
    "    ref = pooled[\"prolonged_reference\"].values\n",
    "    n_norm = (~ref).sum()\n",
    "    fp_rates = [np.sum(~ref & pooled[f\"prolonged_{n}\"].values) / n_norm * 100 for n in names]\n",
    "    order = np.argsort(fp_rates)[::-1]\n",
    "    ax.barh([names[i] for i in order], [fp_rates[i] for i in order],\n",
    "            color=[colors[i] for i in order], edgecolor=\"black\", lw=0.5)\n",
    "    ax.set_xlabel(\"False Positive Rate (% of reference-normals)\", fontsize=12)\n",
    "    ax.set_title(\"B. FP Rates vs Polynomial Reference\", fontsize=13, fontweight=\"bold\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / \"clinical_impact.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Plotting not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Per-Dataset Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for ds in DERIVATION_DATASETS:\n",
    "    if ds not in datasets: continue\n",
    "    df = datasets[ds]\n",
    "    n = len(df)\n",
    "    ref_ds = df[\"prolonged_reference\"].values\n",
    "    row = {\"Dataset\": ds, \"N\": f\"{n:,}\"}\n",
    "    for fname in [\"Marconi\", \"Bazett\", \"Fridericia\"]:\n",
    "        row[f\"|r| {fname}\"] = round(pearson_abs_r(df[f\"QTc_{fname}\"].values, df[\"HR\"].values), 4)\n",
    "    for fname in [\"Marconi\", \"Bazett\"]:\n",
    "        fp = np.sum(~ref_ds & df[f\"prolonged_{fname}\"].values)\n",
    "        n_norm = np.sum(~ref_ds)\n",
    "        row[f\"FP% {fname}\"] = round(fp / n_norm * 100, 2) if n_norm > 0 else 0\n",
    "    rows.append(row)\n",
    "\n",
    "per_ds = pd.DataFrame(rows)\n",
    "print(per_ds.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary\n",
    "\n",
    "This notebook reproduces the core findings using the correct methodology:\n",
    "\n",
    "1. **Primary endpoint (Table 2):** Population-weighted |r(QTc, HR)| confirms Marconi achieves the best heart rate independence.\n",
    "2. **Stratified analysis (Table 3):** Improvement is consistent across HR zones and age groups.\n",
    "3. **External validation (Table 5):** LUDB gold standard confirms zero misclassifications.\n",
    "4. **False positives:** Computed against the per-dataset polynomial reference, showing consistent reduction vs Bazett.\n",
    "5. **Safety (Table 6):** Clinically significant errors (>10ms) substantially reduced.\n",
    "\n",
    "**Methodology reminders:**\n",
    "- Polynomial reference fitted per-dataset (not pooled)\n",
    "- |r| is population-weighted (per-dataset |r| × dataset size)\n",
    "- FP = formula-prolonged AND reference-normal\n",
    "\n",
    "---\n",
    "*Generated by Kepler-ECG validation pipeline. See `validation/reproduce_results.py` for the standalone CLI version.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
